{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23646e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4fee1e",
   "metadata": {},
   "source": [
    "### **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e35816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/maryam/llamaPersonaResp/Data/common/train_data_id.pkl', 'rb') as f:\n",
    "  train_data_id = pickle.load(f)\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/test_data_id.pkl', 'rb') as f:\n",
    "  test_data_id = pickle.load(f)\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/dev_data_id.pkl', 'rb') as f:\n",
    "  dev_data_id = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0adfb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/maryam/llamaPersonaResp/Data/common/train_response_user.pkl', 'rb') as f:\n",
    "    train_response_user = pickle.load(f)\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/test_response_user.pkl', 'rb') as f:\n",
    "    test_response_user = pickle.load(f)\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/dev_response_user.pkl', 'rb') as f:\n",
    "    dev_response_user = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac7669d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/maryam/llamaPersonaResp/Data/common/user_messages.pkl', 'rb') as f:\n",
    "    user_messages = pickle.load(f)\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/wikipedia_conv.pkl', 'rb') as f:\n",
    "    wikipedia = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c0719c",
   "metadata": {},
   "source": [
    "### **Functions to Generate Train/Test/Dev Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51315655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# This function maps the ids in the DH to their real texts\n",
    "# ========================================================\n",
    "def id_to_text(id_histories, dataset):\n",
    "    utterance_dict = {}\n",
    "    for _ , conversation in dataset.items():\n",
    "        for utterance in conversation:\n",
    "            utterance_dict[utterance['id']] = utterance['text']\n",
    "\n",
    "    text_histories = []\n",
    "    for history, response_id in id_histories:\n",
    "        text_history = [utterance_dict[utt_id] for utt_id in history if utt_id in utterance_dict]\n",
    "        true_response = utterance_dict.get(response_id, \"\")\n",
    "        text_history = '__eou__'.join(text_history)\n",
    "        text_histories.append((text_history, true_response))\n",
    "\n",
    "\n",
    "    return text_histories, utterance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2331848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_data(text_histories, wrong_response):\n",
    "  final_list = []\n",
    "  for (history, correct_response), wrong_response in zip(text_histories, wrong_response):\n",
    "      # Randomly choose between the correct and wrong response\n",
    "      if random.choice([True, False]):\n",
    "          chosen_response = correct_response\n",
    "          label = 1  # 1 if true response chosen\n",
    "      else:\n",
    "          chosen_response = wrong_response\n",
    "          label = 0  # 0 if wrong response chosen\n",
    "      # Append a tuple to the final list: (history, chosen_response, label)\n",
    "      final_list.append((history, chosen_response, label))\n",
    "\n",
    "  return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "612cc5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# Creating Distractor list among same user's all responses.\n",
    "# =============================================================\n",
    "def get_distractor(response_user):\n",
    "  distractor_list = []\n",
    "  for user in response_user:\n",
    "    distractor = random.choice(list(user_messages[user]))\n",
    "    distractor_list.append(distractor)\n",
    "\n",
    "  return distractor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ac815d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_data(text_histories, wrong_response):\n",
    "  final_list = []\n",
    "  for (history, correct_response), wrong_response in zip(text_histories, wrong_response):\n",
    "      # Randomly choose between the correct and wrong response\n",
    "      if random.choice([True, False]):\n",
    "          chosen_response = correct_response\n",
    "          label = 1  # 1 if true response chosen\n",
    "      else:\n",
    "          chosen_response = wrong_response\n",
    "          label = 0  # 0 if wrong response chosen\n",
    "      # Append a tuple to the final list: (history, chosen_response, label)\n",
    "      final_list.append((history, chosen_response, label))\n",
    "\n",
    "  return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7a28f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distractor = get_distractor(train_response_user)\n",
    "dev_distractor = get_distractor(dev_response_user)\n",
    "test_distractor = get_distractor(test_response_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1b9eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distractor = get_distractor(train_response_user)\n",
    "dev_distractor = get_distractor(dev_response_user)\n",
    "test_distractor = get_distractor(test_response_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b90b6647",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_histories, utterance_dict = id_to_text(train_data_id, wikipedia)\n",
    "dev_text_histories, utterance_dict = id_to_text(dev_data_id, wikipedia)\n",
    "test_text_histories, utterance_dict = id_to_text(test_data_id, wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dda56d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_data = generate_final_data(train_text_histories, train_distractor)\n",
    "final_dev_data = generate_final_data(dev_text_histories, dev_distractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c398b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data = [\n",
    "    [history[0], history[1], wrong_response]\n",
    "    for history, wrong_response in zip(test_text_histories, test_distractor)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed4d59a",
   "metadata": {},
   "source": [
    "### **Save the data w.o userprofiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a599293",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/maryam/llamaPersonaResp/Data/data_w.o_profile/final_train.pkl', 'wb') as f:\n",
    "  pickle.dump(final_train_data, f)\n",
    "\n",
    "with open('/home/maryam/llamaPersonaResp/Data/data_w.o_profile/final_dev.pkl', 'wb') as f:\n",
    "  pickle.dump(final_dev_data, f)\n",
    "\n",
    "with open('/home/maryam/llamaPersonaResp/Data/data_w.o_profile/final_test.pkl', 'wb') as f:\n",
    "  pickle.dump(final_test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2e5fd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I wanted to let you know that I\\'ve archived the FAC for [[Merry Xmas Everybody]].  This is primarily to give you time to track down a copy of the Holder bio and possibly the Pedler book.  If you get the books more quickly, feel free to ignore the \\\\\"several weeks before renomination\\\\\" rule and bring the article book sooner. Good luck! __eou__Kinda pointless as the article was intended to be nominated for a main page appearance on Christmas Day. I don\\'t need a copy of the Pedler book, it\\'s on Google books, and the Holder bio is unlikely to add anything to it. The best plan is to just leave it, and know that it is a FA just without the pretty star. \\'\\'\\'__eou__Without \\\\\"the pretty star\\\\\" it isn\\'t an FA Majorly. ;-) Why not take Karanacs up on her offer? I would. --__eou__There is no way I\\'ll be able to get either book in enough time. \\'\\'\\'__eou__Christmas comes every year.... Perhaps it can be featured next year? ',\n",
       " \"Yeah sure, just request at [[WP:RFA]]. Good luck <s>Sam<\\\\/s>Deanna! '''\",\n",
       " 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e581b8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
