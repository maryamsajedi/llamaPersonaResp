{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0Z5Pj4-R6MSY"
   },
   "outputs": [],
   "source": [
    "import json, pickle, json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/maryam/llamaPersonaResp/Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elNGAsIkhxy_"
   },
   "source": [
    "### **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "kxYyBMgeXJTF"
   },
   "outputs": [],
   "source": [
    "def read_jsonl_file(file_path):\n",
    "  \"\"\"Reads a JSONL file and returns a list of dictionaries.\"\"\"\n",
    "  data = []\n",
    "  with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "      try:\n",
    "        data.append(json.loads(line))\n",
    "      except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "  return data\n",
    "\n",
    "\n",
    "file_path = f'{path}/original/wikipedia.jsonl'\n",
    "data = read_jsonl_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkB-3j3aRgtu"
   },
   "outputs": [],
   "source": [
    "# create conversations based on the root\n",
    "wikipedia = defaultdict(list)\n",
    "for utterance in data:\n",
    "    wikipedia[utterance['root']].append(utterance)\n",
    "    \n",
    "# Save the conversations to a pickle file\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/wikipedia_conv.pkl', 'wb') as f:\n",
    "    pickle.dump(wikipedia, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1CbRke05eU1"
   },
   "outputs": [],
   "source": [
    "# Dictionary of all the messages each user sent\n",
    "user_messages = defaultdict(list)\n",
    "for root, conversation in wikipedia.items():\n",
    "  for utterance in conversation:\n",
    "    user = utterance['user']\n",
    "    message = utterance['text']\n",
    "    user_messages[user].append(message)\n",
    "\n",
    "# Save the user messages to a pickle file\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/user_messages.pkl', 'wb') as handle:\n",
    "    pickle.dump(user_messages, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate Dialouge History for each conversation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07dOvj2B5gmL"
   },
   "outputs": [],
   "source": [
    "def generate_histories(conversation):\n",
    "    history_dict = {}\n",
    "    for message in conversation:\n",
    "        current_id = message['id']\n",
    "        reply_to = message['reply-to']\n",
    "        if reply_to is None:\n",
    "            history_dict[current_id] = [current_id]\n",
    "        else:\n",
    "            if reply_to in history_dict:\n",
    "                history_dict[current_id] = history_dict[reply_to] + [current_id]\n",
    "            else:\n",
    "                history_dict[current_id] = [reply_to, current_id]\n",
    "    return history_dict\n",
    "\n",
    "def extract_dialogue_histories(conversations):\n",
    "    dialogue_histories = []\n",
    "    seen_histories = set()\n",
    "\n",
    "    for conversation in conversations:\n",
    "        history_dict = generate_histories(conversation)\n",
    "        for message in conversation:\n",
    "            current_id = message['id']\n",
    "            reply_to = message['reply-to']\n",
    "            if reply_to is not None:\n",
    "                history = tuple(history_dict[current_id][:-1][-8:])\n",
    "                history = tuple(history_dict[current_id][:-1])\n",
    "                if history not in seen_histories:\n",
    "                    dialogue_histories.append((history, current_id))\n",
    "                    seen_histories.add(history)\n",
    "\n",
    "    return dialogue_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_histories = extract_dialogue_histories(wikipedia.values())\n",
    "# Save the dialogue histories to a pickle file\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/dialogue_histories.pkl', 'wb') as f:\n",
    "    pickle.dump(dialogue_histories, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Split DH to Train/Test/Dev**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1744545641617,
     "user": {
      "displayName": "Maryam Sajedinia",
      "userId": "08562897053091381387"
     },
     "user_tz": -120
    },
    "id": "HH05XFUyc-pq",
    "outputId": "31452f09-2158-4338-e3e4-61d52fded616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 171935\n",
      "Test data size: 21492\n",
      "Dev data size: 21492\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(dialogue_histories)\n",
    "\n",
    "total_samples = len(dialogue_histories)\n",
    "train_split = int(0.8 * total_samples)\n",
    "test_split = int(0.9 * total_samples)\n",
    "\n",
    "train_data = dialogue_histories[:train_split]\n",
    "test_data = dialogue_histories[train_split:test_split]\n",
    "dev_data = dialogue_histories[test_split:]\n",
    "\n",
    "print(\"Train data size:\", len(train_data))\n",
    "print(\"Test data size:\", len(test_data))\n",
    "print(\"Dev data size:\", len(dev_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UHCqOT5sHh2n"
   },
   "outputs": [],
   "source": [
    "with open('/home/maryam/llamaPersonaResp/Data/common/train_data_id.pkl', 'wb') as f:\n",
    "  pickle.dump(train_data, f)\n",
    "\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/test_data_id.pkl', 'wb') as f:\n",
    "  pickle.dump(test_data, f)\n",
    "\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/dev_data_id.pkl', 'wb') as f:\n",
    "  pickle.dump(dev_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5aNjjUVhZajd"
   },
   "outputs": [],
   "source": [
    "# ======================================================================================================\n",
    "# This function returns last user in the conversation (the one we are going to select the response for)\n",
    "# ======================================================================================================\n",
    "\n",
    "def get_user(id_histories, dataset):\n",
    "  response_user_map = {}\n",
    "  for user, conversation in dataset.items():\n",
    "      for utterance in conversation:\n",
    "          response_user_map[utterance['id']] = utterance['user']\n",
    "  response_user = []\n",
    "  for history, response_id in id_histories:\n",
    "      if response_id in response_user_map:\n",
    "          response_user.append(response_user_map[response_id])\n",
    "\n",
    "  return response_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "pzE9iiyMZzFW"
   },
   "outputs": [],
   "source": [
    "train_response_user = get_user(train_data, wikipedia)\n",
    "dev_response_user = get_user(dev_data, wikipedia)\n",
    "test_response_user = get_user(test_data, wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/maryam/llamaPersonaResp/Data/common/train_response_user.pkl', 'wb') as f:\n",
    "    pickle.dump(train_response_user, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/dev_response_user.pkl', 'wb') as f:\n",
    "    pickle.dump(dev_response_user, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/test_response_user.pkl', 'wb') as f:\n",
    "    pickle.dump(test_response_user, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Bvgd8yszyrIA",
    "BL0Tk7pWRItx",
    "SKrVqdjxFVxn"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
