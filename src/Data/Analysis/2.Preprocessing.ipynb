{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0Z5Pj4-R6MSY"
   },
   "outputs": [],
   "source": [
    "import json, pickle, json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/maryam/llamaPersonaResp/Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elNGAsIkhxy_"
   },
   "source": [
    "### **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/maryam/llamaPersonaResp/Data/common/wikipedia_conv.pkl', 'rb') as file:\n",
    "    wikipedia = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save last-user and last-utterance\n",
    "gtruth = []\n",
    "for root, conversations in wikipedia.items():\n",
    "        last_user = conversations[-1]['user']\n",
    "        last_utterance = conversations[-1]['text']\n",
    "        gtruth.append((last_user, last_utterance))\n",
    "with open(path + '/wikipedia_gtruth.json', 'w') as f:\n",
    "    json.dump(gtruth, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_for_profiles = defaultdict(list)\n",
    "\n",
    "for root, conversation in wikipedia.items():\n",
    "    if not conversation:\n",
    "        continue\n",
    "    last_user = conversation[-1]['user']\n",
    "    for utterance in conversation:\n",
    "        if utterance['user'] == last_user and utterance['text'].strip():\n",
    "            user_for_profiles[last_user].append(utterance['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/maryam/llamaPersonaResp/Data/common/user_messages_profile.pkl', 'wb') as handle:\n",
    "    pickle.dump(user_for_profiles, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "F1CbRke05eU1"
   },
   "outputs": [],
   "source": [
    "# Dictionary of all the messages each user sent\n",
    "user_messages = defaultdict(list)\n",
    "for root, conversation in wikipedia.items():\n",
    "  for utterance in conversation:\n",
    "    user = utterance['user']\n",
    "    message = utterance['text']\n",
    "    user_messages[user].append(message)\n",
    "\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/user_messages.pkl', 'wb') as handle:\n",
    "    pickle.dump(user_messages, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate Dialouge History for each conversation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "07dOvj2B5gmL"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def generate_histories(conversation):\n",
    "    children = defaultdict(list)\n",
    "    id_to_message = {}\n",
    "    root_id = None\n",
    "\n",
    "    for message in conversation:\n",
    "        current_id = int(message['id'])\n",
    "        reply_to = message['reply_to']\n",
    "        id_to_message[current_id] = message\n",
    "        if reply_to is not None:\n",
    "            children[int(reply_to)].append(current_id)\n",
    "        else:\n",
    "            root_id = current_id\n",
    "\n",
    "    # Now do DFS from root to build all paths\n",
    "    all_paths = []\n",
    "\n",
    "    def dfs(node, path):\n",
    "        path.append(node)\n",
    "        if node not in children or len(children[node]) == 0:\n",
    "            all_paths.append(path.copy())\n",
    "        else:\n",
    "            for child in children[node]:\n",
    "                dfs(child, path)\n",
    "        path.pop()\n",
    "\n",
    "    if root_id is not None:\n",
    "        dfs(root_id, [])\n",
    "\n",
    "    return all_paths, id_to_message\n",
    "\n",
    "\n",
    "def extract_dialogue_histories(conversations):\n",
    "    dialogue_histories = []\n",
    "    utterance_dict = {}\n",
    "\n",
    "    for conversation in conversations:\n",
    "        paths, id_to_message = generate_histories(conversation)\n",
    "\n",
    "        # Collect utterance text\n",
    "        for msg_id, msg in id_to_message.items():\n",
    "            utterance_dict[int(msg_id)] = msg['text']\n",
    "\n",
    "        # Extract history-response pairs from paths\n",
    "        for path in paths:\n",
    "            for i in range(1, len(path)):\n",
    "                history = tuple(path[:i])\n",
    "                response_id = path[i]\n",
    "                dialogue_histories.append((history, response_id))\n",
    "\n",
    "    return dialogue_histories, utterance_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_histories, utterance_dict = extract_dialogue_histories(wikipedia.values())\n",
    "# Save the dialogue histories to a pickle file\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/dialogue_histories_id.pkl', 'wb') as f:\n",
    "    pickle.dump(dialogue_histories, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/utterance_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(utterance_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Split DH to Train/Test/Dev**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1744545641617,
     "user": {
      "displayName": "Maryam Sajedinia",
      "userId": "08562897053091381387"
     },
     "user_tz": -120
    },
    "id": "HH05XFUyc-pq",
    "outputId": "31452f09-2158-4338-e3e4-61d52fded616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 211343\n",
      "Test data size: 26418\n",
      "Dev data size: 26418\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(dialogue_histories)\n",
    "\n",
    "total_samples = len(dialogue_histories)\n",
    "train_split = int(0.8 * total_samples)\n",
    "test_split = int(0.9 * total_samples)\n",
    "\n",
    "train_data = dialogue_histories[:train_split]\n",
    "test_data = dialogue_histories[train_split:test_split]\n",
    "dev_data = dialogue_histories[test_split:]\n",
    "\n",
    "print(\"Train data size:\", len(train_data))\n",
    "print(\"Test data size:\", len(test_data))\n",
    "print(\"Dev data size:\", len(dev_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UHCqOT5sHh2n"
   },
   "outputs": [],
   "source": [
    "with open('/home/maryam/llamaPersonaResp/Data/common/train_data_id.pkl', 'wb') as f:\n",
    "  pickle.dump(train_data, f)\n",
    "\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/test_data_id.pkl', 'wb') as f:\n",
    "  pickle.dump(test_data, f)\n",
    "\n",
    "with open('/home/maryam/llamaPersonaResp/Data/common/dev_data_id.pkl', 'wb') as f:\n",
    "  pickle.dump(dev_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Bvgd8yszyrIA",
    "BL0Tk7pWRItx",
    "SKrVqdjxFVxn"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
