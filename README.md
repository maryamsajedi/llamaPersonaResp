# llamaPersonaGen

**User-specific response generation/selection using LLaMA 3.2 Instruct**

This project explores how user profiles influence response selection and generation in dialogue systems. It leverages the LLaMA 3.2 Instruct model to generate/select contextual, personalized responses based on user-specific information.

## ğŸš€ Features

- Response selection and generation using `LLaMA 3.2 Instruct`
- Dynamic prompt construction based on user profiles
- Evaluation of sentiment and personalization impact
- Clean, modular code for experimentation and extension

## ğŸ§  Research Goal

To investigate the impact of user profiles on dialogue response quality and relevance, focusing on both generation and selection tasks.

## ğŸ› ï¸ Requirements

- Python 3.8+
- PyTorch
- HuggingFace Transformers
- Any LLaMA 3.2 Instruct-compatible inference backend (e.g., `transformers`, `vllm`, or `llama.cpp`)

## ğŸ“ Project Structure

